---
title: "Web scraping"
author: "Hye Soo Choi"
date: "July 30, 2015"
output: html_document
---

-----

## Getting Started with Web Scraping

Let's check the __Mail Code List__ pages from the _UC Berkeley Mail Services_ website: [http://mailservices.berkeley.edu/incoming/mailcodes/list](http://mailservices.berkeley.edu/incoming/mailcodes/list)

Note that the first page shows the departments "90.7 FM, AAS, ..., AHMA" and their respective codes. Then, at the bottom of the page you'll see a series of links numbered `1, 2, 3, 4, 5, 6, 7, 8, 9, ..., next> last>>`

__The purpose of this session is to scrape all the deparments and their mail codes.__

-----

## Looking at the HTML source code

Let's inspect the source html code. The first 3 departments (90.7 FM, AAS, and ACADEMIC ACHIEVEMENT PROGRAMS) appear in lines 209-211 within nodes like these:
```{r eval=FALSE}
<tr class="odd">
  <td class="view-field view-field-node-title active">90.7 FM</td>
  <td class="view-field view-field-node-data-field-code-field-code-value">5650</td> </tr>
<tr class="even">
  <td class="view-field view-field-node-title active">AAS</td>
  <td class="view-field view-field-node-data-field-code-field-code-value">2572</td> </tr>
<tr class="odd">
  <td class="view-field view-field-node-title active">ACADEMIC ACHIEVEMENT PROGRAMS</td>
  <td class="view-field view-field-node-data-field-code-field-code-value">2410</td> 
</tr>
```

We can match each department's name node with the following __XPath__ pattern:
```{r, eval=FALSE}
'//td[@class="view-field view-field-node-title active"]'
```

Likewise, we can match each department's code node with the following __XPath__ pattern:
```{r, eval=FALSE}
'//td[@class="view-field view-field-node-data-field-code-field-code-value"]'
```


-----

## Scraping Page 1

Let's scrape the first page:
```{r, eval=TRUE}
# load XML
library(XML)

# parsing html content
page1 <- htmlParse('http://mailservices.berkeley.edu/incoming/mailcodes/list')
```

How would you get the department names and codes?
```{r, eval = TRUE}
# department names
xpathSApply(doc = page1,
            path = '//td[@class="view-field view-field-node-title active"]',
            xmlValue)


# department codes
xpathSApply(doc = page1,
            path = '//td[@class="view-field view-field-node-data-field-code-field-code-value"]',
            xmlValue)



# ----
```


-----

## Scraping the first 5 pages

Instead of just scraping the first page, let's crawl through the first 5 pages: 1, 2, 3, 4, 5 

__Your mission is to obtain a data frame with two columns: `department` and `code`, and as many rows as departments.__

Brainstorm with your neighbors:

- How would you scrape the first 5 pages?
- Think about all the steps you need to perform
- Think about the data objects you may use to store the scraped content

```{r}
# scraping UC Berkeley Mail Codes
names <- character(0)
codes <- character(0)
for (i in 0:4){
  address <- paste0('http://mailservices.berkeley.edu/incoming/mailcodes/list?page=',i)
  page <- htmlParse(address)
  names <- c(names, 
             xpathSApply(doc = page,
            path = '//td[@class="view-field view-field-node-title active"]',
            xmlValue))
  codes <-  c(codes, 
             xpathSApply(doc = page,
            path = '//td[@class="view-field view-field-node-data-field-code-field-code-value"]',
            xmlValue))
  
}


# ----
```

-----

## Scraping all the pages

Instead of just scraping the first 5 pages, you'll have to crawl through every single page: 1, 2, 3, 4, ... 

- How many pages you have to crawl over?
- Try to write functions that help you get the job done

```{r}
# scraping UC Berkeley Mail Codes
library('RCurl')
names <- character(0)
codes <- character(0)
i <- 0
repeat{
  address <- paste0('http://mailservices.berkeley.edu/incoming/mailcodes/list?page=',i)
  if(!url.exists(address)){
    break
  }
  page <- htmlParse(address)
  names <- c(names, 
             xpathSApply(doc = page,
            path = '//td[@class="view-field view-field-node-title active"]',
            xmlValue))
  codes <-  c(codes, 
             xpathSApply(doc = page,
            path = '//td[@class="view-field view-field-node-data-field-code-field-code-value"]',
            xmlValue))
  i <- i + 1
}

url.exists('http://mailservices.berkeley.edu/incoming/mailcodes/list?page=100')

# ----
```
